{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import ast\n",
    "tqdm.pandas()\n",
    "from sqlalchemy import create_engine, URL\n",
    "from rapidfuzz import fuzz, process, distance\n",
    "from rapidfuzz.distance import Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rel_on_science = pd.read_json('/mnt/hdd01/patentsview/Reliance on Science - Cleantech Patents/df_oaid_cleantech_lang_detect_yake_title_abstract_noun_chunks.json')\n",
    "df_patstat = pd.read_json('/mnt/hdd01/PATSTAT Working Directory/PATSTAT/df_patstat_cleantech_granted_abstract_metadata.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_patstat = df_patstat[df_patstat['appln_auth'].apply(lambda x: 'US' in x or 'EP' in x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_oaid = df_rel_on_science['id'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patstat_appln_id = df_patstat['appln_id'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Author Information from PATSTAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patstat_url_object = URL.create(\n",
    "    drivername=\"postgresql+psycopg2\",\n",
    "    username=\"tie\",\n",
    "    password=\"TIE%2023!tuhh\",\n",
    "    # host=\"134.28.58.100\",\n",
    "    host=\"100.113.100.152\",\n",
    "    port=\"65432\",\n",
    "    database=\"PATSTAT_2023\",\n",
    ")\n",
    "engine = create_engine(patstat_url_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patstat_appln_id_str = ', '.join(map(str, patstat_appln_id))\n",
    "\n",
    "query = f\"\"\"\n",
    "SELECT pa.appln_id, p.person_id, p.person_name, p.person_name_orig_lg, p.doc_std_name, p.psn_name, p.han_name\n",
    "FROM tls206_person AS p\n",
    "INNER JOIN (\n",
    "    SELECT appln_id, person_id\n",
    "    FROM tls207_pers_appln\n",
    "    WHERE CAST(appln_id AS INTEGER) IN ({patstat_appln_id_str})\n",
    ") AS pa ON p.person_id = pa.person_id\n",
    "\"\"\"\n",
    "df_patstat_authors = pd.read_sql_query(query, engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_patstat_authors.to_csv('/mnt/hdd01/Cleantech Network Analysis/df_patstat_authors.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_patstat_authors = pd.read_csv('/mnt/hdd01/Cleantech Network Analysis/df_patstat_authors.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Author Information from OpenAlex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oa_url_object = URL.create(\n",
    "    drivername=\"postgresql+psycopg2\",\n",
    "    username=\"tie\",\n",
    "    password=\"TIE%2023!tuhh\",\n",
    "    # host=\"134.28.58.100\",\n",
    "    host=\"100.113.100.152\",\n",
    "    port=\"45432\",\n",
    "    database=\"openalex_db\",\n",
    ")\n",
    "engine = create_engine(oa_url_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_oa_authors = pd.DataFrame()\n",
    "\n",
    "chunk_size = 10000\n",
    "rel_oaid_chunks = [rel_oaid[i:i + chunk_size] for i in range(0, len(rel_oaid), chunk_size)]\n",
    "\n",
    "for rel_oaid_chunk in tqdm(rel_oaid_chunks):\n",
    "    rel_oaid_str = ', '.join(map(repr, rel_oaid_chunk))\n",
    "    query = f\"\"\"\n",
    "    SELECT wa.work_id, a.id, a.display_name, a.display_name_alternatives\n",
    "    FROM openalex.authors AS a\n",
    "    INNER JOIN (\n",
    "        SELECT work_id, author_id\n",
    "        FROM openalex.works_authorships\n",
    "        WHERE work_id IN ({rel_oaid_str})\n",
    "    ) AS wa ON a.id = wa.author_id\n",
    "    \"\"\"\n",
    "    df_chunk = pd.read_sql_query(query, engine)\n",
    "    df_oa_authors = pd.concat([df_oa_authors, df_chunk])\n",
    "\n",
    "df_oa_authors.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_oa_authors.to_csv(\"/mnt/hdd01/Cleantech Network Analysis/df_oa_authors.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_oa_authors = pd.read_csv(\"/mnt/hdd01/Cleantech Network Analysis/df_oa_authors.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge Authors from PATSTAT and OpenAlex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_oa_authors['display_name_alternatives'] = df_oa_authors['display_name_alternatives'].apply(lambda x: ast.literal_eval(x)) # already a list\n",
    "df_oa_authors['display_name_alternatives'] = df_oa_authors.apply(lambda row: row['display_name_alternatives'] + [row['display_name']] if isinstance(row['display_name_alternatives'], list) else [row['display_name']], axis=1)\n",
    "df_oa_authors_exploded = df_oa_authors.explode('display_name_alternatives')\n",
    "df_oa_authors_exploded['oaid'] = df_oa_authors_exploded['work_id'].apply(lambda x: x.replace(\"https://openalex.org/W\", \"\"))\n",
    "df_oa_authors_exploded['display_name_alternatives'].dropna(inplace=True)\n",
    "df_oa_authors_exploded['display_name_alternatives'] = df_oa_authors_exploded['display_name_alternatives'].apply(lambda x: x.lower() if isinstance(x, str) else x)\n",
    "df_oa_authors_exploded.dropna(subset=['display_name_alternatives'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_patstat_authors =df_patstat_authors.drop_duplicates(subset=['appln_id', 'person_id'])\n",
    "df_patstat_authors_melted = df_patstat_authors.melt(id_vars=['appln_id', 'person_id'], \n",
    "                                                                  value_vars=['person_name', 'person_name_orig_lg', 'doc_std_name', 'psn_name', 'han_name'],\n",
    "                                                                  var_name='name_type', \n",
    "                                                                  value_name='name')\n",
    "df_patstat_authors_melted['name'] = df_patstat_authors_melted['name'].apply(lambda x: x.lower() if isinstance(x, str) else x)\n",
    "df_patstat_authors_melted['appln_id'] = df_patstat_authors_melted['appln_id'].astype(str)\n",
    "df_patstat['appln_id'] = df_patstat['appln_id'].astype(str)\n",
    "df_patstat_authors_melted = pd.merge(df_patstat_authors_melted, df_patstat[['appln_id']], on='appln_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rel_pcs = pd.read_csv(\"/mnt/hdd01/Reliance on Science/Raw Files/_pcs_oa.csv\") # Only merge authors if patent-paper citation is present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rel_pcs['patent_id_prefix'] = df_rel_pcs['patent'].apply(lambda x: x.split('-')[0])\n",
    "df_rel_pcs['patent_id'] = df_rel_pcs['patent'].apply(lambda x: '-'.join(x.split('-')[1:-1]))\n",
    "df_rel_pcs = df_rel_pcs[df_rel_pcs['patent_id_prefix'].isin(['us', 'ep'])]\n",
    "df_rel_pcs = df_rel_pcs[df_rel_pcs['oaid'].isin(df_rel_on_science['oaid'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Appln_id from PATSTAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patstat_url_object = URL.create(\n",
    "    drivername=\"postgresql+psycopg2\",\n",
    "    username=\"tie\",\n",
    "    password=\"TIE%2023!tuhh\",\n",
    "    # host=\"134.28.58.100\",\n",
    "    host=\"100.113.100.152\",\n",
    "    port=\"65432\",\n",
    "    database=\"PATSTAT_2023\",\n",
    ")\n",
    "engine = create_engine(patstat_url_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rel_pcs['patent_id_prefix'] = df_rel_pcs['patent_id_prefix'].apply(lambda x: x.upper())\n",
    "df_rel_pcs.to_sql('temp_df_rel_pcs', engine, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT temp.patent_id, temp.patent_id_prefix, publn.appln_id\n",
    "FROM temp_df_rel_pcs AS temp\n",
    "INNER JOIN tls211_pat_publn AS publn\n",
    "ON temp.patent_id = publn.publn_nr AND temp.patent_id_prefix = publn.publn_auth\n",
    "\"\"\"\n",
    "df_result = pd.read_sql_query(query, engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result['patent_id_prefix_patent_id'] = df_result['patent_id_prefix'] + '-' + df_result['patent_id']\n",
    "df_rel_pcs['patent_id_prefix_patent_id'] = df_rel_pcs['patent_id_prefix'] + '-' + df_rel_pcs['patent_id']\n",
    "df_rel_pcs.drop(columns=['patent', 'wherefound', 'confscore', 'self', 'reftype'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = df_result[['patent_id_prefix_patent_id', 'appln_id']]\n",
    "df_rel_pcs = df_rel_pcs[['oaid', 'patent_id_prefix_patent_id']]\n",
    "\n",
    "df_result.set_index('patent_id_prefix_patent_id', inplace=True)\n",
    "df_rel_pcs.set_index('patent_id_prefix_patent_id', inplace=True)\n",
    "\n",
    "df_rel_pcs = df_rel_pcs.join(df_result, how='left')\n",
    "\n",
    "df_rel_pcs.reset_index(inplace=True)\n",
    "df_rel_pcs.drop_duplicates(subset=['oaid', 'appln_id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rel_pcs_grouped = df_rel_pcs.groupby('appln_id').agg({'oaid': list}).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_patstat_authors_melted['appln_id'] = df_patstat_authors_melted['appln_id'].astype(str)\n",
    "df_rel_pcs_grouped['appln_id'] = df_rel_pcs_grouped['appln_id'].astype(str)\n",
    "df_patstat_authors_melted = pd.merge(df_patstat_authors_melted, df_rel_pcs_grouped[['oaid', 'appln_id']], left_on='appln_id', right_on='appln_id', how='inner', validate='m:m')\n",
    "# df_patstat_person_details_melted = df_patstat_person_details_melted.dropna(subset=['oaid'])\n",
    "df_patstat_authors_melted = df_patstat_authors_melted.dropna(subset=['appln_id'])\n",
    "df_patstat_authors_exploded = df_patstat_authors_melted.explode('oaid')\n",
    "df_patstat_authors_exploded = df_patstat_authors_exploded.dropna(subset=['oaid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_oa_authors_exploded_exploded = df_oa_authors_exploded.explode('oaid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_patstat_authors_exploded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_oa_authors_exploded_exploded.rename(columns={'id': 'author_id'}, inplace=True)\n",
    "df_oa_authors_exploded_exploded['oaid'] = df_oa_authors_exploded_exploded['oaid'].astype(str)\n",
    "df_oa_authors_exploded_exploded.set_index('oaid', inplace=True)\n",
    "\n",
    "df_patstat_authors_exploded['oaid'] = df_patstat_authors_exploded['oaid'].astype(str)\n",
    "df_patstat_authors_exploded.set_index('oaid', inplace=True)\n",
    "\n",
    "df_merged = df_oa_authors_exploded_exploded.join(df_patstat_authors_exploded, how='inner')\n",
    "\n",
    "df_merged = df_merged[['appln_id', 'person_id', 'name_type', 'name', 'author_id', 'display_name', 'display_name_alternatives']]\n",
    "df_merged.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_names(row):\n",
    "    full_name = row['name']\n",
    "    match = distance.Levenshtein.normalized_similarity(full_name, row['display_name_alternatives'])\n",
    "    return match\n",
    "\n",
    "df_merged['best_match'] = df_merged.progress_apply(match_names, axis=1)\n",
    "# df_merged_test['best_match'] = df_merged_test.progress_apply(match_names, axis=1)\n",
    "\n",
    "# df_merged = df_merged.sort_values('best_match', ascending=False)\n",
    "df_merged_filtered = df_merged[df_merged['best_match'] >= 0.75]\n",
    "df_merged_filtered = df_merged_filtered.loc[df_merged_filtered.groupby(['appln_id', 'person_id', 'oaid', 'author_id', 'display_name'])['best_match'].idxmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_patstat_authors_filtered = df_patstat_authors[~df_patstat_authors[['appln_id', 'person_id']].apply(tuple, 1).isin(df_merged_filtered[['appln_id', 'person_id']].apply(tuple, 1))]\n",
    "df_patstat_authors_filtered = df_patstat_authors_filtered.drop_duplicates(subset=['appln_id', 'person_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_patstat_authors['appln_id'] = df_patstat_authors_filtered['appln_id'].astype(str)\n",
    "df_patstat['appln_id'] = df_patstat['appln_id'].astype(str)\n",
    "df_patstat_authors_filtered['appln_id'] = df_patstat_authors_filtered['appln_id'].astype(str)\n",
    "df_patstat['appln_id'] = df_patstat['appln_id'].astype(str)\n",
    "df_patstat_authors_filtered = pd.merge(df_patstat_authors_filtered, df_patstat, on='appln_id', how='inner', validate='m:m')\n",
    "# df_patstat_authors_filtered = df_patstat_authors_filtered.rename(columns={'publn_nr': 'patent_id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_oa_authors_exploded_exploded = df_oa_authors_exploded_exploded.reset_index()\n",
    "df_oa_authors_filtered = df_oa_authors_exploded_exploded[~df_oa_authors_exploded_exploded[['oaid', 'author_id']].apply(tuple, 1).isin(df_merged_filtered[['oaid', 'author_id']].apply(tuple, 1))]\n",
    "df_oa_authors_filtered = df_oa_authors_filtered.drop_duplicates(subset=['oaid', 'author_id'])\n",
    "df_oa_authors_filtered = df_oa_authors_filtered[['oaid', 'author_id', 'display_name', 'display_name_alternatives']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_authors = pd.concat([df_merged_filtered, df_patstat_authors_filtered, df_oa_authors_filtered], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_authors.drop_duplicates(subset=['appln_id', 'person_id', 'oaid', 'author_id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_authors.to_csv('/mnt/hdd01/Cleantech Network Analysis/df_authors.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
