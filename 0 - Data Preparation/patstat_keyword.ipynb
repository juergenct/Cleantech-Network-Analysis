{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "# import cudf.pandas\n",
    "# cudf.pandas.install()\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleantech_keywords = pd.read_json(\"/home/thiesen/Documents/Cleantech_Concepts/cleantech_keywords_similarity_015_co_occurrence_025_claim_fulltext.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_patstat = pd.read_json('/mnt/hdd01/PATSTAT Working Directory/PATSTAT/df_patstat_cleantech_granted_abstract_metadata.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_patstat = df_patstat[df_patstat['appln_auth'].apply(lambda x: 'US' in x or 'EP' in x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 696354/696354 [00:00<00:00, 881732.49it/s]\n",
      "100%|██████████| 696354/696354 [00:00<00:00, 848781.37it/s]\n",
      "100%|██████████| 696354/696354 [03:12<00:00, 3625.52it/s]\n"
     ]
    }
   ],
   "source": [
    "df_patstat['appln_title'] = df_patstat['appln_title'].progress_apply(lambda x: ' '.join([i if i is not None else '' for i in x])).str.lower()\n",
    "df_patstat['appln_abstract'] = df_patstat['appln_abstract'].progress_apply(lambda x: ' '.join([i if i is not None else '' for i in x])).str.lower()\n",
    "df_patstat['title_abstract'] = df_patstat['appln_title'] + ' ' + df_patstat['appln_abstract']\n",
    "df_patstat['title_abstract_lemma'] = df_patstat['title_abstract'].progress_apply(lambda x: ' '.join([lemmatizer.lemmatize(word) for word in x.split()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Document-Term Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrams = df_cleantech_keywords['keyword_yake_lemma'].tolist()\n",
    "documents = df_patstat['title_abstract_lemma'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_tokenizer(text, ngrams):\n",
    "    pattern = '|'.join(re.escape(phrase) for phrase in ngrams)\n",
    "    tokens = []\n",
    "    last_end = 0\n",
    "    for match in re.finditer(pattern, text):\n",
    "        tokens.extend(text[last_end:match.start()].split())\n",
    "        tokens.append(match.group(0))\n",
    "        last_end = match.end()\n",
    "    tokens.extend(text[last_end:].split())\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer_wrapper(text):\n",
    "    return custom_tokenizer(text, ngrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(tokenizer=tokenizer_wrapper, vocabulary=ngrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thiesen/Documents/Cleantech-Network-Analysis/venv/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "patstat_cleantech_dtm = vectorizer.fit_transform(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_patstat_cleantech_dtm = pd.DataFrame(patstat_cleantech_dtm.toarray(),\n",
    "                                        columns=vectorizer.get_feature_names_out())\n",
    "df_patstat_cleantech_dtm.reset_index(drop=True, inplace=True)\n",
    "df_patstat.reset_index(drop=True, inplace=True)\n",
    "df_patstat_cleantech_dtm.insert(0, 'appln_id', df_patstat['appln_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_patstat_cleantech_dtm.to_csv('/mnt/hdd01/Cleantech Network Analysis/df_patstat_cleantech_dtm.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
